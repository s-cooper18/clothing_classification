{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data investigation\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['data_exploration.ipynb',\n '.DS_Store',\n 'export.pkl',\n 'multi_labels.csv',\n 'prediction_evaluation.ipynb',\n 'apparel-dataset',\n 'apparel-dataset.zip',\n '.gitignore',\n 'Model_training.ipynb',\n '.git',\n 'multilabel_subset.csv']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/sucooper/Documents/brown-bag/clothing-classifier/clothing_classification\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already loaded\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "if 'apparel-dataset' not in os.listdir():\n",
    "    if 'apparel-dataset.zip' not in os.listdir():\n",
    "        print('Dataset has not been downloaded. Downloading now from kaggle')\n",
    "        !kaggle datasets download -d kaiska/apparel-dataset\n",
    "    # unzip\n",
    "    !unzip apparel-dataset.zip -d ./apparel-dataset\n",
    "# move dataset into the correct location\n",
    "else:\n",
    "    print(\"Dataset already loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabulate the kinds of data\n",
    "df = pd.DataFrame([item.split('_') for item in os.listdir('apparel-dataset')])\n",
    "df.columns = ['Colour', 'Item']\n",
    "df['Count'] = [len(os.listdir('apparel-dataset/' + item)) for item in os.listdir('apparel-dataset')]\n",
    "df['Count'] = df['Count'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Item</th>\n      <th>dress</th>\n      <th>hoodie</th>\n      <th>pants</th>\n      <th>shirt</th>\n      <th>shoes</th>\n      <th>shorts</th>\n      <th>skirt</th>\n      <th>suit</th>\n    </tr>\n    <tr>\n      <th>Colour</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>black</th>\n      <td>450</td>\n      <td>136</td>\n      <td>870</td>\n      <td>715</td>\n      <td>766</td>\n      <td>328</td>\n      <td>126</td>\n      <td>320</td>\n    </tr>\n    <tr>\n      <th>blue</th>\n      <td>502</td>\n      <td>131</td>\n      <td>798</td>\n      <td>741</td>\n      <td>523</td>\n      <td>299</td>\n      <td>126</td>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>brown</th>\n      <td>117</td>\n      <td>188</td>\n      <td>311</td>\n      <td>127</td>\n      <td>464</td>\n      <td>127</td>\n      <td>137</td>\n      <td>133</td>\n    </tr>\n    <tr>\n      <th>green</th>\n      <td>119</td>\n      <td>118</td>\n      <td>227</td>\n      <td>230</td>\n      <td>455</td>\n      <td>135</td>\n      <td>114</td>\n      <td>243</td>\n    </tr>\n    <tr>\n      <th>pink</th>\n      <td>136</td>\n      <td>347</td>\n      <td>246</td>\n      <td>132</td>\n      <td>144</td>\n      <td>137</td>\n      <td>513</td>\n      <td>137</td>\n    </tr>\n    <tr>\n      <th>red</th>\n      <td>800</td>\n      <td>349</td>\n      <td>308</td>\n      <td>332</td>\n      <td>610</td>\n      <td>133</td>\n      <td>130</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>silver</th>\n      <td>133</td>\n      <td>125</td>\n      <td>119</td>\n      <td>123</td>\n      <td>403</td>\n      <td>126</td>\n      <td>361</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>white</th>\n      <td>818</td>\n      <td>138</td>\n      <td>274</td>\n      <td>133</td>\n      <td>600</td>\n      <td>120</td>\n      <td>132</td>\n      <td>354</td>\n    </tr>\n    <tr>\n      <th>yellow</th>\n      <td>566</td>\n      <td>131</td>\n      <td>127</td>\n      <td>139</td>\n      <td>145</td>\n      <td>195</td>\n      <td>409</td>\n      <td>143</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "Item    dress  hoodie  pants  shirt  shoes  shorts  skirt  suit\nColour                                                         \nblack     450     136    870    715    766     328    126   320\nblue      502     131    798    741    523     299    126   136\nbrown     117     188    311    127    464     127    137   133\ngreen     119     118    227    230    455     135    114   243\npink      136     347    246    132    144     137    513   137\nred       800     349    308    332    610     133    130   130\nsilver    133     125    119    123    403     126    361   127\nwhite     818     138    274    133    600     120    132   354\nyellow    566     131    127    139    145     195    409   143"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaped_df = df.pivot(index='Colour', columns='Item', values='Count')\n",
    "shaped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import get_image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_cat = 10\n",
    "subset = [{\"filename\": 'apparel-dataset/' + parent + '/' + filename, \"labels\": parent } for parent in os.listdir(Path('apparel-dataset')) for filename in os.listdir('apparel-dataset/' + parent)[0:n_per_cat]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(subset).to_csv(\"labels_subset_10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "present = [{\"Colour\": row[\"Colour\"], \"Item\": row[\"Item\"]} for row in df.iloc()]\n",
    "all_combinations = [{\"Colour\": i, \"Item\": j} for i in df['Colour'].unique() for j in df['Item'].unique()]\n",
    "\n",
    "difference = [row for row in all_combinations if row not in present]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "35"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the ones to get images for\n",
    "items_to_obtain = [row['Colour'] + '_' + row['Item'] for row in difference]\n",
    "len(items_to_obtain)\n",
    "\n",
    "\n",
    "# obtain images for each of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Item</th>\n      <th>dress</th>\n      <th>hoodie</th>\n      <th>pants</th>\n      <th>shirt</th>\n      <th>shoes</th>\n      <th>shorts</th>\n      <th>skirt</th>\n      <th>suit</th>\n    </tr>\n    <tr>\n      <th>Colour</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>black</th>\n      <td>450.0</td>\n      <td>0.0</td>\n      <td>870.0</td>\n      <td>715.0</td>\n      <td>766.0</td>\n      <td>328.0</td>\n      <td>0.0</td>\n      <td>320.0</td>\n    </tr>\n    <tr>\n      <th>blue</th>\n      <td>502.0</td>\n      <td>0.0</td>\n      <td>798.0</td>\n      <td>741.0</td>\n      <td>523.0</td>\n      <td>299.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>brown</th>\n      <td>0.0</td>\n      <td>188.0</td>\n      <td>311.0</td>\n      <td>0.0</td>\n      <td>464.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>green</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>227.0</td>\n      <td>230.0</td>\n      <td>455.0</td>\n      <td>135.0</td>\n      <td>0.0</td>\n      <td>243.0</td>\n    </tr>\n    <tr>\n      <th>pink</th>\n      <td>0.0</td>\n      <td>347.0</td>\n      <td>246.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>513.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>red</th>\n      <td>800.0</td>\n      <td>349.0</td>\n      <td>308.0</td>\n      <td>332.0</td>\n      <td>610.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>silver</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>403.0</td>\n      <td>0.0</td>\n      <td>361.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>white</th>\n      <td>818.0</td>\n      <td>0.0</td>\n      <td>274.0</td>\n      <td>0.0</td>\n      <td>600.0</td>\n      <td>120.0</td>\n      <td>0.0</td>\n      <td>354.0</td>\n    </tr>\n    <tr>\n      <th>yellow</th>\n      <td>566.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>195.0</td>\n      <td>409.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "Item    dress  hoodie  pants  shirt  shoes  shorts  skirt   suit\nColour                                                          \nblack   450.0     0.0  870.0  715.0  766.0   328.0    0.0  320.0\nblue    502.0     0.0  798.0  741.0  523.0   299.0    0.0    0.0\nbrown     0.0   188.0  311.0    0.0  464.0     0.0    0.0    0.0\ngreen     0.0     0.0  227.0  230.0  455.0   135.0    0.0  243.0\npink      0.0   347.0  246.0    0.0    0.0     0.0  513.0    0.0\nred     800.0   349.0  308.0  332.0  610.0     0.0    0.0    0.0\nsilver    0.0     0.0    0.0    0.0  403.0     0.0  361.0    0.0\nwhite   818.0     0.0  274.0    0.0  600.0   120.0    0.0  354.0\nyellow  566.0     0.0    0.0    0.0    0.0   195.0  409.0    0.0"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shaped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-search-imagesearch in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from azure-cognitiveservices-search-imagesearch) (1.1.27)\n",
      "Requirement already satisfied: msrest>=0.5.0 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from azure-cognitiveservices-search-imagesearch) (0.6.21)\n",
      "Requirement already satisfied: msrestazure<2.0.0,>=0.4.32 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from azure-cognitiveservices-search-imagesearch) (0.6.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (1.3.0)\n",
      "Requirement already satisfied: requests~=2.16 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (2021.5.30)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (0.6.0)\n",
      "Requirement already satisfied: six in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (1.16.0)\n",
      "Requirement already satisfied: adal<2.0.0,>=0.6.0 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (1.2.7)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.1.0 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from adal<2.0.0,>=0.6.0->msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (2.8.1)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from adal<2.0.0,>=0.6.0->msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (2.1.0)\n",
      "Requirement already satisfied: cryptography>=1.1.0 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from adal<2.0.0,>=0.6.0->msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (3.4.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from cryptography>=1.1.0->adal<2.0.0,>=0.6.0->msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=1.1.0->adal<2.0.0,>=0.6.0->msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (2.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (3.1.1)\n",
      "Requirement already satisfied: graphviz in /Users/sucooper/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages (0.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-cognitiveservices-search-imagesearch\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import ImageClassifierCleaner\n",
    "from azure.cognitiveservices.search.imagesearch import ImageSearchClient as api\n",
    "from msrest.authentication import CognitiveServicesCredentials as auth\n",
    "from pathlib import Path\n",
    "\n",
    "def search_images_bing(key, term, min_sz=128):\n",
    "    client = api('https://api.bing.microsoft.com', auth(key))\n",
    "    return L(client.images.search(query=term, count=150, min_height=min_sz, min_width=min_sz).value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for additional images in bing\n",
    "from fastbook import search_images_bing, download_images\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.environ.get('AZURE_SEARCH_KEY', 'e74445748f594211a2cd25e2abd455ce')\n",
    "path = Path('collected_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_images_bing(key, \"green_skirt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = \"collected_data/green_skirt\"\n",
    "download_images(dest, urls=results.attrgot('contentUrl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Download of http://www.bridalshoesuk.co.uk/product_images/r/384/LUXEFUSCH_PAIR__85539_zoom.jpg has failed after 5 retries\n",
      " Fix the download manually:\n",
      "$ mkdir -p collected_data/pink_shoes\n",
      "$ cd collected_data/pink_shoes\n",
      "$ wget -c http://www.bridalshoesuk.co.uk/product_images/r/384/LUXEFUSCH_PAIR__85539_zoom.jpg\n",
      "$ tar xf LUXEFUSCH_PAIR__85539_zoom.jpg\n",
      " And re-run your code once the download is successful\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for o in items_to_obtain[1:]:\n",
    "    dest = (path/o)\n",
    "    if not dest.exists():\n",
    "        dest.mkdir(exist_ok=True)\n",
    "        results = search_images_bing(key, o)\n",
    "        download_images(dest, urls=results.attrgot('contentUrl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorResponseException",
     "evalue": "Operation returned an invalid status code 'Resource Not Found'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mErrorResponseException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vc/x0m1lt7j0fz_mzm_jlrcx6v00000gn/T/ipykernel_18180/759815291.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_images_bing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"green_skirt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/vc/x0m1lt7j0fz_mzm_jlrcx6v00000gn/T/ipykernel_18180/3298570370.py\u001b[0m in \u001b[0;36msearch_images_bing\u001b[0;34m(key, term, min_sz)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msearch_images_bing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_sz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://api.bing.microsoft.com'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/brown-bag/flask-clothing-classifier/.venv/lib/python3.9/site-packages/azure/cognitiveservices/search/imagesearch/operations/_images_operations.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, query, accept_language, user_agent, client_id, client_ip, location, aspect, color, country_code, count, freshness, height, id, image_content, image_type, license, market, max_file_size, max_height, max_width, min_file_size, min_height, min_width, offset, safe_search, size, set_lang, width, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mErrorResponseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mErrorResponseException\u001b[0m: Operation returned an invalid status code 'Resource Not Found'"
     ]
    }
   ],
   "source": [
    "results = search_images_bing(key, \"green_skirt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to multilabel format\n",
    "dataset_dir = Path('apparel-dataset')\n",
    "# create a csv file with | filelocation | labels |\n",
    "fns = get_image_files(dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{\"fname\":image, \"labels\":image.parent.name.replace('_', ' ')} for image in fns]\n",
    "csv_labels = pd.DataFrame(labels)\n",
    "csv_labels.to_csv('multi_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sub dataset\n",
    "subset = [{\"fname\": 'apparel-dataset/' + cat +'/' + i, \"labels\":cat.replace('_', ' ')} for cat in os.listdir('apparel-dataset') for i in os.listdir('apparel-dataset/' + cat)[0:10]]\n",
    "subset_df = pd.DataFrame(subset)\n",
    "subset_df.to_csv('multilabel_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Block and Category Block\n",
    "filename = 'multilabel_subset.csv'\n",
    "multilables = pd.read_csv(filename)\n",
    "\n",
    "# Turning it into a multilabel data block\n",
    "path = Path('.')\n",
    "def get_x(r): return path/r['fname']\n",
    "def get_y(r): return r['labels'].split(' ')\n",
    "dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock), get_x = get_x, get_y = get_y, item_tfms=RandomResizedCrop(128, min_scale=0.35))\n",
    "dsets = dblock.datasets(multilables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(#370) [(PILImage mode=RGB size=256x256, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])),(PILImage mode=RGB size=256x256, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])),(PILImage mode=RGB size=256x256, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])),(PILImage mode=RGB size=256x256, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])),(PILImage mode=RGB size=256x256, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])),(PILImage mode=RGB size=256x256, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])),(PILImage mode=RGB size=256x256, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])),(PILImage mode=RGB size=256x256, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])),(PILImage mode=RGB size=256x256, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])),(PILImage mode=RGB size=256x256, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]))...]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(12936, 3234)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dsets.train),len(dsets.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilabel training\n",
    "clothes = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=RandomResizedCrop(460, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms(size=224, min_scale=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('.venv': venv)",
   "name": "python395jvsc74a57bd0ef4a00f2d98425f6015ad7d2d367adf9d9590185d8af77ca57b9c8b381bc0d32"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}